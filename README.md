# portfolio
ðŸ”— [Portfolio website](https://ruthdorton.com/portfolio)
## UFOs | [GitHub](https://github.com/RuthLD/UFOs)
Use JavaScript to create a dynamic webpage for information related to UFO sightings. The webpage allows the UFO information to be filtered by five search criteria: Date, City, State, Country, and shape.
* I created a function in JavaScript that allowed for any combination of the search criteria to be inputted into the webpage and return the results in a table.
* Tools: JavaScript, HTML
* ![Enter_site.gif](https://github.com/RuthLD/UFOs/blob/main/Resources/Enter_site.gif)
## State Plant Analysis | [GitHub](https://github.com/RuthLD/State_Plant_Analysis)
Using Python to determine the most common plants in New York state using data from the PLANTS Database. The goal was to determine the counts and percentages of the plants recorded in New York state to evaluate biodiversity. 
* I used Python and Matplotlib to create charts and tables for the ten most common plants by three scientific classivication levels: Family, Genus, Species/Scientific Name
* Tools: Python, Jupyter Notebook, Matplotlib, Pandas
* ![classification_percent.png](https://github.com/RuthLD/State_Plant_Analysis/blob/main/Resources/classification_percent.png)
## Mission to Mars | [GitHub](https://github.com/RuthLD/Mission_to_Mars)
Use web scraping to visit and collect the most recent new about the plant Mars. The most recent new article and description, the Featured image, facts about the weather on Mars, and images of the four hemispheres of Mars were the targets for the project.
* I used BeautifulSoup create a function to visit four different sites to scrape the required data and images. Then I used Flask to create a webpage to display the data with the capability to run a new data scrape. The page html is [here](https://github.com/RuthLD/Mission_to_Mars/blob/main/templates/index.html).
* Tools: Python, Jupyter Notebook, HTML, Pandas, BeautifulSoup, Flask, Splinter, MongoDB
## Surfs Up | [GitHub](https://github.com/RuthLD/surfs_up)
The goal of the analysis is to investigate the temperature trends for investors of a surf shop. Weather data from the months of June and December were compared to determine if the business is sustainable year-round.
* I created summary statistic tables to compare recorded temperatures and precipitation. I used Flask to create a webpage to display the information collected.
* Tools: Python, Jupyter Notebook, Pandas, NumPy, Matplotlib, SQLalchemy, Flask
* ![June_temp_stats.png](https://github.com/RuthLD/surfs_up/blob/main/Resources/June_temp_stats.png) ![Dec_temp_stats.png](https://github.com/RuthLD/surfs_up/blob/main/Resources/Dec_temp_stats.png)
## Pewlett Hackard Employee Databases | [GitHub](https://github.com/RuthLD/Pewlett_Hackard_Analysis)
The purpose of the analysis was to identify the number of near retirement employees by job title and identify employees who were eligible to participate in a mentorship program. 
* I was responsible for calculating the total number of titles and the number of unique titles held by retirement eligible employees using SQL queries. I also produced a table to show the number of retiring employees by department.
* Tools: PostgreSQL
* ![titles_by_dept.png](https://github.com/RuthLD/Pewlett_Hackard_Analysis/blob/main/Resources/titles_by_dept.png) ![mentorship_count.png](https://github.com/RuthLD/Pewlett_Hackard_Analysis/blob/main/Resources/mentorship_count.png)
## Movie ETL | [GitHub](https://github.com/RuthLD/Movie_ETL)
Extract the movie data from Wikipedia and Kaggle from their respective files, transform the datasets by cleaning them and merging them together, then load the cleaned dataset into a SQL database.
* I created functions to clean and condense the data while dropping null values from the datasets.
* Tools: Python, Jupyter Notebook, PostgreSQL, NumPy, SQLalchemy
## World Weather Analysis | [GitHub](https://github.com/RuthLD/World_Weather_Analysis)
The project was to collect and analyze weather date from cities worldwide using APIs to recommend hotels based on weather preferences. The NumPy module was used to generate more than 2000 random latitudes and longitudes, and the citypy module was used to list the nearest city to the latitudes and longitudes. 
* A travel destination map and a travel itinerary map were the two item I produced. The travel destination map received input for a minimum and maximum temperature and the hotels were collected using Googleâ€™s Maps and Places API and Search Nearby feature. The travel itinerary shows the routes between four cities based on the weather preferences. 
* Tools: Python, Jupyter Notebook, Pandas, NumPy, citypy, APIs
* ![WeatherPy_vacation_map.png](https://github.com/RuthLD/World_Weather_Analysis/blob/main/Vacation_Search/WeatherPy_vacation_map.png)
## PyBer Analysis | [GitHub](https://github.com/RuthLD/PyBer_Analysis)
The goal was to analyze ride-sharing data from January to early May 2019 based on the city type. The three key metrics evaluated were the total number of rides, total fares collected, and the total number of drivers.
* Responsible for the descriptive statistics for the rideshare data and creating compelling visualizations. Provided recommendations to increase earnings for each city type based on the data.
* Tools: Python, Jupyter Notebooks, Pandas, NumPy, SciPy, Matplotlib
* ![PyBer_fare_summary.png](https://github.com/RuthLD/PyBer_Analysis/blob/main/analysis/PyBer_fare_summary.png)
* ![Table1_PyberSummary.png](https://github.com/RuthLD/PyBer_Analysis/blob/main/analysis/Table1_PyberSummary.png)
## School District Analysis | [GitHub](https://github.com/RuthLD/School_District_Analysis)
The goal was to present a high-level snapshot of the school districtâ€™s math and reading test scores. The analysis looked at the difference in test performance by school size, type, and funding.
* I was responsible for using Jupyter Notebook to write Python code to view the top 5 and bottom 5 performing schools and format the district metrics into tables.
* Tools: Python, Jupyter Notebook, Pandas
* ![Corrected_School_Perfromance_by_School_Size.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_School_Perfromance_by_School_Size.png)
* ![Corrected_Perform_by_school_type.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_Perform_by_school_type.png)
* ![Corrected_Perform_by_budget_per_student.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_Perform_by_budget_per_student.png)
## Election Analysis | [GitHub](https://github.com/RuthLD/Election_Analysis)
The task was to complete the election audit of a recent congressional election including a complete list of candidates with the total number of votes each candidate received.
* I was responsible for the create of for loops to calculate the number of votes by county and for candidate.
* Tools: Python, VSCode
## Green Stock Analysis | [GitHub](https://github.com/RuthLD/stock-analysis)
The goal of the analysis was to evaluate green energy company stocks to assess the potential for diversification of an investment fund. The stock data was compared based on changes from 2017 to 2018.
* I was responsible for refactoring the code to improve the run time of the script.
* Tools: Microsoft Excel, VBA
## Kickstarter Campaigns | [GitHub](https://github.com/RuthLD/kickstarter-analysis)
The project was an analysis of Kickstarter data to identify trends from previous successfully funded Kickstarter campaigns. The goal was to provide recommendations for a theater production campaign with a target of $10,000 based on the identified trends.
* I was responsible for cleaning and filtering the data before using pivot tables and charts to complete the analysis.
* Tools: Microsoft Excel
* ![Parent Category_Outcomes.pg](https://github.com/RuthLD/kickstarter-analysis/blob/main/resources/Parent%20Category_Outcomes.png)
* ![Theater_Outcomes_vs_Launch.png](https://github.com/RuthLD/kickstarter-analysis/blob/main/resources/Theater_Outcomes_vs_Launch.png)
