# Project Summaries
ðŸ”— [Portfolio website](https://ruthdorton.com/portfolio)
ðŸ”—[Tableau Portfolio](https://public.tableau.com/profile/ruth.dorton#!/?newProfile=&activeTab=0)
## Heart Disease Prediction | Group Project | [Github](https://github.com/pasmi369/Heart_Analysis_Detection_Project)
For the group project, I worked with Pashmina Sangani, Hulya Nohut, and Maria Gribbon. The goal was to apply as many of the tools we learned in the nineteen previous weeks. we wanted to focus on health, so we found a large dataset related to cardiovascular disease prediction. The data was downloaded from [Kaggle](https://www.kaggle.com/sulianova/cardiovascular-disease-dataset/). I handled the code for the learning models portion of the group project. I also wrote a summary of the final project for my [blog](https://ruthdorton.com/blog/f/bootcamp-group-project-reflection).
* ![SMOTEENN_test_accuracy.png](https://github.com/pasmi369/Heart_Analysis_Detection_Project/blob/main/Resources/SMOTEENN_test_accuracy.png)
* ![SMOTE_Oversampling_test_accuracy.png](https://github.com/pasmi369/Heart_Analysis_Detection_Project/blob/main/Resources/SMOTE_Oversampling_test_accuracy.png)
## Amazon Vine Analysis | [Github](https://github.com/RuthLD/Amazon_Vine_Analysis)
The purpose of this analysis was to use PySpark to perform the ETL process to extract the dataset, transform the data, connect to an AWS RDS instance, and load the transformed data into pgAdmin. 
* PySpark to determine if there is any bias toward favorable reviews from Vine members in the Digital Video Game Reviews dataset
* ![paid_reviews.png](https://github.com/RuthLD/Amazon_Vine_Analysis/blob/main/Resources/paid_reviews.png)
* Tools: Postgres, Jupyter Notebook, PySpark
## MechaCar Statistical Analysis | [Github](https://github.com/RuthLD/MechaCar_Statistical_Analysis)
A statistical analysis of MechaCar vehicles and a study designed to compare the MechaCar vehicles to R.
* Use Linear Regression to predict MPG for MechaCar vehicles and t.tests to determine if there is a statistical difference in the different manufacturing lots of suspension coils.
* ![Fig_1.png](https://github.com/RuthLD/MechaCar_Statistical_Analysis/blob/main/Resources/Fig_1.png)
* Provide a study ouline for comparing MechaCar vehicles to a competitor.
* Tools: R
## Bikesharing | [GitHub](https://github.com/RuthLD/bikesharing ) ðŸ”—[Tableau Story](https://public.tableau.com/app/profile/ruth.dorton/viz/NYCCitiBikeChallenge_16208606980650/NYCCitiBikeChallenge)
Used data from the Citi Bike program in New York City to create visualizations in Tableau for an investor presentation.
* Build insightful charts for an investor presentation using Tableau.
* Use data from a peak summer month in New York City from Citi Biki to evaluate who would use a bike-sharing program and when the most active ridership would be. 
* ![NYC%20CitiBike%20Challenge_7.png](https://github.com/RuthLD/bikesharing/blob/main/Resources/NYC%20CitiBike%20Challenge_7.png) 
## Mapping Earthquakes | [GitHub](https://github.com/RuthLD/Mapping_Earthquakes)
Using the Mapbox API create an interactive map with Leafletjs to display the last seven days of earthquake from GeoJson data from earthquake.usgs.gov.
* I created an interactive map with three options for the base map and three layer that can be changed by the user to view the data.
* Tools: JavaScript, HTML, CSS, Mapbox API, Leafletjs, geoJSON
* ![Change_Map.gif](https://github.com/RuthLD/Mapping_Earthquakes/blob/main/Earthquake_Challenge/Resources/Change_Map.gif)
## Belly Button Biodiversity Study | [GitHub](https://github.com/RuthLD/plotly_chart)
Use plotly and JavaScript to create a webpage showing the samples for each volunteer by the individual ID.
* I created functions in JavaScript that allowed for the volunteer number to be changed using a drop-down selection on the webpage. This updated three charts to reflect the results by volunteer.
* Tools: JavaScript, HTML, Plotly
* ![Defult_site.gif](https://github.com/RuthLD/plotly_chart/blob/master/Resources/Defult_site.gif)
## UFOs | [GitHub](https://github.com/RuthLD/UFOs)
Use JavaScript to create a dynamic webpage for information related to UFO sightings. The webpage allows the UFO information to be filtered by five search criteria: Date, City, State, Country, and shape.
* I created a function in JavaScript that allowed for any combination of the search criteria to be inputted into the webpage and return the results in a table.
* Tools: JavaScript, HTML
* ![Enter_site.gif](https://github.com/RuthLD/UFOs/blob/main/Resources/Enter_site.gif)
## Mission to Mars | [GitHub](https://github.com/RuthLD/Mission_to_Mars)
Use web scraping to visit and collect the most recent new about the plant Mars. The most recent new article and description, the Featured image, facts about the weather on Mars, and images of the four hemispheres of Mars were the targets for the project.
* I used BeautifulSoup create a function to visit four different sites to scrape the required data and images. Then I used Flask to create a webpage to display the data with the capability to run a new data scrape. The page html is [here](https://github.com/RuthLD/Mission_to_Mars/blob/main/templates/index.html).
* Tools: Python, Jupyter Notebook, HTML, Pandas, BeautifulSoup, Flask, Splinter, MongoDB
## Surfs Up | [GitHub](https://github.com/RuthLD/surfs_up)
The goal of the analysis is to investigate the temperature trends for investors of a surf shop. Weather data from the months of June and December were compared to determine if the business is sustainable year-round.
* I created summary statistic tables to compare recorded temperatures and precipitation. I used Flask to create a webpage to display the information collected.
* Tools: Python, Jupyter Notebook, Pandas, NumPy, Matplotlib, SQLalchemy, Flask
* ![June_temp_stats.png](https://github.com/RuthLD/surfs_up/blob/main/Resources/June_temp_stats.png) ![Dec_temp_stats.png](https://github.com/RuthLD/surfs_up/blob/main/Resources/Dec_temp_stats.png)
## Pewlett Hackard Employee Databases | [GitHub](https://github.com/RuthLD/Pewlett_Hackard_Analysis)
The purpose of the analysis was to identify the number of near retirement employees by job title and identify employees who were eligible to participate in a mentorship program. 
* I was responsible for calculating the total number of titles and the number of unique titles held by retirement eligible employees using SQL queries. I also produced a table to show the number of retiring employees by department.
* Tools: PostgreSQL
* ![titles_by_dept.png](https://github.com/RuthLD/Pewlett_Hackard_Analysis/blob/main/Resources/titles_by_dept.png) ![mentorship_count.png](https://github.com/RuthLD/Pewlett_Hackard_Analysis/blob/main/Resources/mentorship_count.png)
## Movie ETL | [GitHub](https://github.com/RuthLD/Movie_ETL)
Extract the movie data from Wikipedia and Kaggle from their respective files, transform the datasets by cleaning them and merging them together, then load the cleaned dataset into a SQL database.
* I created functions to clean and condense the data while dropping null values from the datasets.
* Tools: Python, Jupyter Notebook, PostgreSQL, NumPy, SQLalchemy
## World Weather Analysis | [GitHub](https://github.com/RuthLD/World_Weather_Analysis)
The project was to collect and analyze weather date from cities worldwide using APIs to recommend hotels based on weather preferences. The NumPy module was used to generate more than 2000 random latitudes and longitudes, and the citypy module was used to list the nearest city to the latitudes and longitudes. 
* A travel destination map and a travel itinerary map were the two item I produced. The travel destination map received input for a minimum and maximum temperature and the hotels were collected using Googleâ€™s Maps and Places API and Search Nearby feature. The travel itinerary shows the routes between four cities based on the weather preferences. 
* Tools: Python, Jupyter Notebook, Pandas, NumPy, citypy, APIs
* ![WeatherPy_vacation_map.png](https://github.com/RuthLD/World_Weather_Analysis/blob/main/Vacation_Search/WeatherPy_vacation_map.png)
## PyBer Analysis | [GitHub](https://github.com/RuthLD/PyBer_Analysis)
The goal was to analyze ride-sharing data from January to early May 2019 based on the city type. The three key metrics evaluated were the total number of rides, total fares collected, and the total number of drivers.
* Responsible for the descriptive statistics for the rideshare data and creating compelling visualizations. Provided recommendations to increase earnings for each city type based on the data.
* Tools: Python, Jupyter Notebooks, Pandas, NumPy, SciPy, Matplotlib
* ![PyBer_fare_summary.png](https://github.com/RuthLD/PyBer_Analysis/blob/main/analysis/PyBer_fare_summary.png)
* ![Table1_PyberSummary.png](https://github.com/RuthLD/PyBer_Analysis/blob/main/analysis/Table1_PyberSummary.png)
## School District Analysis | [GitHub](https://github.com/RuthLD/School_District_Analysis)
The goal was to present a high-level snapshot of the school districtâ€™s math and reading test scores. The analysis looked at the difference in test performance by school size, type, and funding.
* I was responsible for using Jupyter Notebook to write Python code to view the top 5 and bottom 5 performing schools and format the district metrics into tables.
* Tools: Python, Jupyter Notebook, Pandas
* ![Corrected_School_Perfromance_by_School_Size.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_School_Perfromance_by_School_Size.png)
* ![Corrected_Perform_by_school_type.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_Perform_by_school_type.png)
* ![Corrected_Perform_by_budget_per_student.png](https://github.com/RuthLD/School_District_Analysis/blob/main/Resources/Corrected_Perform_by_budget_per_student.png)
## Election Analysis | [GitHub](https://github.com/RuthLD/Election_Analysis)
The task was to complete the election audit of a recent congressional election including a complete list of candidates with the total number of votes each candidate received.
* I was responsible for the create of for loops to calculate the number of votes by county and for candidate.
* Tools: Python, VSCode
## Green Stock Analysis | [GitHub](https://github.com/RuthLD/stock-analysis)
The goal of the analysis was to evaluate green energy company stocks to assess the potential for diversification of an investment fund. The stock data was compared based on changes from 2017 to 2018.
* I was responsible for refactoring the code to improve the run time of the script.
* Tools: Microsoft Excel, VBA
## Kickstarter Campaigns | [GitHub](https://github.com/RuthLD/kickstarter-analysis)
The project was an analysis of Kickstarter data to identify trends from previous successfully funded Kickstarter campaigns. The goal was to provide recommendations for a theater production campaign with a target of $10,000 based on the identified trends.
* I was responsible for cleaning and filtering the data before using pivot tables and charts to complete the analysis.
* Tools: Microsoft Excel
* ![Parent Category_Outcomes.pg](https://github.com/RuthLD/kickstarter-analysis/blob/main/resources/Parent%20Category_Outcomes.png)
* ![Theater_Outcomes_vs_Launch.png](https://github.com/RuthLD/kickstarter-analysis/blob/main/resources/Theater_Outcomes_vs_Launch.png)
